from bs4 import BeautifulSoup
from selenium import webdriver


driver = webdriver.Chrome('C:/Users/Ariel/Downloads/chromedriver_win32/chromedriver')
driver.implicitly_wait(3)

driver.get('http://1.231.29.235/Account/LogOn')

driver.find_element_by_name('UserName').send_keys('khy4701')
driver.find_element_by_name('Password').send_keys('ghdud159753')

element = driver.find_element_by_xpath("//a[contains(@href,'fnSubmit')]")
element.click()

driver.implicitly_wait(3)

driver.get('http://1.231.29.235/Ea/EADocPop/EAAppDocPop/?form_id=31')

driver.implicitly_wait(5)
element = driver.find_element_by_xpath("//span[@id='cke_32_label']")
element.click()

driver.implicitly_wait(3)

html = driver.page_source
soup = BeautifulSoup(html, 'html.parser')

#div = soup.find('div', id = 'cke_1_contents')

value = soup.findAll("textarea", {"id":"editorarea"})

for val in value:
    print (val.renderContents())
                     
#print( )[0].renderContents())


#print(div.select('textarea')[0].string)
#print (div.contents[0].content())

'''
for paragraph in soup.find_all('textarea'):
    print(paragraph.contents)
    #print(str(paragraph.text))
'''
    

'''
notices = soup.select('#cke_1_contents > textarea')

for n in notices:
    print(n.text.strip())
'''

'''

notices = soup.select('div.p_inr > div.p_info > a > span')

for n in notices:
    print(n.text.strip())
'''



